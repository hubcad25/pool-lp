# Exp√©rimentation: Mod√®les de Projection de Features

## Objectif

Tester et comparer diff√©rents mod√®les pour projeter les **9 variables ind√©pendantes** n√©cessaires aux mod√®les bay√©siens de pr√©diction de points.

**Question centrale:** Quel mod√®le pr√©dit le mieux chaque feature pour la saison suivante?

**D√©cision finale:** S√©lectionner le **meilleur mod√®le PAR FEATURE** (pas un mod√®le unique pour tout).

---

## √âtat actuel

### ‚úÖ Termin√©
- **00_prepare_validation_data.R** - Donn√©es pr√©par√©es (840 joueurs, 1-3 saisons d'historique)
- **01_wma.R** - Weighted Moving Average (Approche 2)
- **02_regression_to_mean.R** - Regression to Mean (Approche 2)
- **03_age_curves_v1.R** - Age Curves V1 (Approche 2)
- **03_age_curves_v2.R** - Age Curves V2 avec splines (Approche 2)
- **04_random_forest.R** - Random Forest (Approche 1) - **GAGNANT**
- **05_xgboost.py** - XGBoost (Approche 1)
- **06_gam.R** - GAM (Approche 1) - Meilleur pour conversion_overall
- **07_lstm.py** - LSTM (Approche 1)
- **notebook/** - Analyse comparative compl√®te avec visualisations

### üìä R√©sultats - D√©cisions finales

**Random Forest domine:**
- Meilleur mod√®le sur **6/9 features** (R¬≤ 0.64-0.86)
- GAM meilleur pour `conversion_overall` (R¬≤ 0.571)
- Conversions granulaires: utiliser league average (R¬≤ n√©gatifs)

Voir `notebook/notebook.html` pour analyse d√©taill√©e.

---

## Setup des donn√©es

### Ex√©cution
```r
source("code/01_point_projections/projection/feature_model_experiments/00_prepare_validation_data.R")
```

### Datasets g√©n√©r√©s
**Localisation:** `data/01_point_projections/projection/experiments/validation_data/`

1. **df_train.rds** (3925 obs, saisons 2020-2023)
2. **df_valid_history.rds** (2430 obs, saisons 2021-2023)
   - Historique des 840 joueurs √† projeter
   - 1 √† 3 saisons par joueur
3. **df_valid_targets.rds** (840 obs, saison 2024)
   - Vraies valeurs 2024 pour comparaison

### Colonnes disponibles
```r
- player_id, name, season, position, age, games_played
- evtoi_per_gp, pptoi_per_gp
- high_danger_shots_per60, medium_danger_shots_per60
- x_goals_per60, shot_attempts_per60
- conversion_high_danger, conversion_medium, conversion_overall
- goals, assists (pour r√©f√©rence)
```

### Distribution des joueurs (validation 2024)
- **840 joueurs** (539 F, 301 D)
- **√Çge:** 19-39 ans (m√©diane 27)
- **Historique:** 630 avec 3 saisons, 101 avec 2, 109 avec 1 seule
- **Games played 2024:** 1-85 GP (m√©diane 68)

---

## Features √† projeter (9 variables)

### Time on Ice (2)
1. `evtoi_per_gp` - Even strength TOI per game (en secondes)
2. `pptoi_per_gp` - Power play TOI per game (en secondes)

### Production (4)
3. `high_danger_shots_per60`
4. `medium_danger_shots_per60`
5. `x_goals_per60`
6. `shot_attempts_per60`

### Conversion rates (3)
7. `conversion_high_danger` - Taux de conversion high danger
8. `conversion_medium` - Taux de conversion medium danger
9. `conversion_overall` - Shooting % global

**Note:** wpm_g et wpm_a ne sont PAS projet√©s - ce sont des calculs arithm√©tiques directs.

---

## Approches de games_played weighting

**‚ö†Ô∏è R√àGLE ABSOLUE:** Tous les mod√®les doivent utiliser `weight = recency_weight √ó (gp / season_length)`

**JAMAIS** utiliser games_played en absolu. Toujours normaliser par la longueur de la saison.

### Saisons √©court√©es
```r
season_lengths <- c(
  "2012" = 48,  # Lockout
  "2020" = 56,  # COVID
  "2021" = 82,
  "2022" = 82,
  "2023" = 82,
  "2024" = 82
)

recency_weight <- c(0.5, 0.3, 0.2)  # t-1, t-2, t-3
```

---

### Approche 1: Weight comme FEATURE
**Pour:** Random Forest, XGBoost, GAM, LSTM

Ces mod√®les **apprennent** comment utiliser les weights. On cr√©e des features explicites.

```r
# Cr√©er features de weight pour chaque p√©riode
df_model <- df_history %>%
  mutate(
    season_length = season_lengths[as.character(season)]
  ) %>%
  arrange(player_id, desc(season)) %>%
  group_by(player_id) %>%
  mutate(
    time_index = row_number(),
    # Calculer weight = recency √ó (gp / season_length)
    weight = case_when(
      time_index == 1 ~ 0.5 * (games_played / season_length),
      time_index == 2 ~ 0.3 * (games_played / season_length),
      time_index == 3 ~ 0.2 * (games_played / season_length)
    )
  ) %>%
  pivot_wider(
    names_from = time_index,
    values_from = c(feature, weight),
    names_glue = "{.value}_t{time_index}"
  )

# Features finales:
# feature_t1, feature_t2, feature_t3
# weight_t1, weight_t2, weight_t3  <-- Le mod√®le apprend √† utiliser √ßa
# age, position
```

**Un seul script par mod√®le** - pas de variantes V1/V2.

---

### Approche 2: Weight comme ARGUMENT
**Pour:** WMA, Regression to Mean, Age Curves

Ces mod√®les utilisent les weights **explicitement** dans leurs calculs.

```r
# Calculer weights pour chaque joueur
df_weighted <- df_history %>%
  mutate(
    season_length = season_lengths[as.character(season)]
  ) %>%
  arrange(player_id, desc(season)) %>%
  group_by(player_id) %>%
  mutate(
    time_index = row_number(),
    recency_weight = case_when(
      time_index == 1 ~ 0.5,
      time_index == 2 ~ 0.3,
      time_index == 3 ~ 0.2,
      TRUE ~ 0
    ),
    gp_weight = games_played / season_length,
    adjusted_weight = recency_weight * gp_weight
  ) %>%
  summarise(
    total_weight = sum(adjusted_weight, na.rm = TRUE),
    # Renormaliser
    projection = sum(feature * (adjusted_weight / total_weight), na.rm = TRUE)
  )
```

**Exemples d'utilisation:**
- **WMA:** `weighted.mean(feature, w = adjusted_weight / sum(adjusted_weight))`
- **RTM:** `volume = sum(shots * gp_weight)`, puis `weight = volume / (volume + k)`
- **Age Curves:** Appliquer sur WMA d√©j√† pond√©r√©e

**Un seul script par mod√®le** - pas de variantes V1/V2.

---

## Mod√®les √† impl√©menter

### 1. ‚úÖ Weighted Moving Average (WMA)
**Script:** `01_wma.R`
**Approche:** Approche 2 (weight comme argument)

**Formule:**
```r
weight = recency_weight √ó (gp / season_length)
projection = weighted.mean(feature, w = weight)
```

**R√©sultats (R¬≤ validation 2024):**
- evtoi_per_gp: 0.71
- x_goals_per60: 0.80
- conversion_overall: 0.51

### 2. Regression to Mean
**Script:** `02_regression_to_mean.R`
**Approche:** Approche 2 (weight comme argument)

**Formule:**
```r
# Volume ajust√© par gp/season_length
volume = sum(shots √ó (gp / season_length))
weight = volume / (volume + k)  # k optimis√© par feature
projection = weight √ó recent_value + (1 - weight) √ó league_avg
```

**Objectif:** Am√©liorer pr√©diction des conversions (tr√®s volatiles)

### 3. Age Curves (Delta Method)
**Script:** `03_age_curves.R`
**Approche:** Approche 2 (appliqu√© sur WMA)

**M√©thode:**
1. Calculer WMA avec weights ajust√©s (gp/season_length)
2. Appliquer facteur d'√¢ge: `projection_final = WMA √ó age_factor(age, position)`
3. Analyser courbes d'√¢ge historiques (2007-2024)

**Note:** Peut avoir variantes sur le facteur (global vs sp√©cifique par feature)

### 4. Random Forest
**Script:** `04_random_forest.R`
**Approche:** Approche 1 (weight comme feature)

**Features:**
- Historique: `feature_t1, feature_t2, feature_t3`
- **Weights:** `weight_t1, weight_t2, weight_t3` (= recency √ó gp/season_length)
- Fixes: `age, position`

**Hyperparam√®tres optimis√©s:**
- ntree: 500, 1000
- mtry: sqrt(p), p/3
- nodesize: 5, 10

### 5. XGBoost
**Script:** `05_xgboost.R`
**Approche:** Approche 1 (weight comme feature)

**Features:** Identiques √† Random Forest

**Hyperparam√®tres:**
- max_depth: 3, 5, 7
- eta: 0.01, 0.05, 0.1
- subsample: 0.7, 0.8
- nrounds: early stopping

### 6. GAM (Generalized Additive Model)
**Script:** `06_gam.R`
**Approche:** Approche 1 (weight comme feature)

**Formule:**
```r
feature_t+1 ~ s(age, k=5) +
              s(feature_t1, k=8) + s(feature_t2, k=8) + s(feature_t3, k=8) +
              s(weight_t1, k=5) + s(weight_t2, k=5) + s(weight_t3, k=5) +
              position +
              te(age, feature_t1, k=c(4,4))
```

### 7. LSTM
**Script:** `07_lstm.R`
**Approche:** Approche 1 (weight comme feature)

**Architecture:**
- Input par timestep: `[feature_t, weight_t, age_t]`
- Window: 1-3 saisons (longueur variable)
- Layers: LSTM(64) ‚Üí Dropout(0.2) ‚Üí Dense(32) ‚Üí Output(1)

### 8. Ensemble
**Script:** `08_ensemble.R`
**Approche:** Combiner meilleurs mod√®les par feature

**M√©thode:**
1. Pour chaque feature, identifier top 3 mod√®les
2. Optimiser poids via validation
3. `pred = w1√ómodel1 + w2√ómodel2 + w3√ómodel3`

---

## Mod√®les sp√©cifiques aux conversions

**Probl√®me:** Les 3 features de conversion (`conversion_high_danger`, `conversion_medium`, `conversion_overall`) sont tr√®s difficiles √† pr√©dire (R¬≤ autour de 0 pour la plupart des mod√®les). Elles contiennent beaucoup plus de **variance/luck** que les autres stats.

**Strat√©gie:** D√©velopper des mod√®les sp√©cialis√©s qui exploitent mieux la structure des donn√©es de conversion.

### √Ä impl√©menter

#### 1. Regression to Mean Agressive (RTM+)
**Script:** `09_rtm_aggressive_conversions.R`

**Concept:** Forcer un shrinkage beaucoup plus fort vers la moyenne de la ligue pour les conversions.

```r
# Pour conversions: forcer k plus √©lev√©
k_conversions <- c(
  conversion_high_danger = 500,   # au lieu de ~100-200 optimis√©
  conversion_medium = 400,
  conversion_overall = 300
)

# Shrink beaucoup plus vers league average
weight = volume / (volume + k_conversions[feature])
projection = weight √ó recent + (1 - weight) √ó league_avg
```

**Hypoth√®se:** Les conversions r√©gressent plus vite que les autres stats ‚Üí besoin de plus de shrinkage.

#### 2. xGoals Residuals Model
**Script:** `10_xgoals_residuals_conversions.R`

**Concept:** Utiliser la diff√©rence entre goals r√©els et xGoals pour quantifier "luck/finishing skill".

```r
# Pour conversion_overall:
# 1. Calculer r√©sidus historiques
xg_residuals <- (goals - x_goals) / shots  # "Luck" par shot

# 2. Regress residuals vers 0
# Hypoth√®se: residuals positifs = chanceux ‚Üí va diminuer
#            residuals n√©gatifs = malchanceux ‚Üí va augmenter

projection_conversion = league_avg_conversion +
                        (xg_residuals √ó decay_factor)

# decay_factor shrinks vers 0 (ex: 0.3)
```

**Features:**
- `xg_residuals_t1, xg_residuals_t2, xg_residuals_t3`
- `shots_volume` (pour confiance dans l'estim√©)
- `age, position`

**Note:** Rabbit hole potentiel - diff√©rencier bons finisseurs vs chanceux. Pour l'instant, on assume que les residuals r√©gressent vers 0.

#### 3. Beta Regression
**Script:** `11_beta_regression_conversions.R`

**Concept:** Les conversions sont des proportions [0,1] ‚Üí utiliser un mod√®le Beta qui respecte cette contrainte.

```r
library(betareg)

# Beta regression naturellement bounded [0,1]
model <- betareg(
  conversion ~ feature_t1 + weight_t1 + age + position,
  data = train_data
)
```

**Avantage:** G√®re mieux les valeurs extr√™mes (proche de 0 ou 1) et variance non-constante.

#### 4. PP/EV Context Separate
**Script:** `12_ppev_context_conversions.R`

**Concept:** La conversion PP est tr√®s diff√©rente de EV ‚Üí mod√©liser s√©par√©ment.

**Probl√®me:** N√©cessite de splitter les donn√©es play-by-play (pas dans dataset actuel).

**√Ä √©valuer:** Est-ce que le jeu vaut la chandelle? Co√ªt/b√©n√©fice de collecter ces donn√©es.

#### 5. Rolling Average Long (4-5 saisons)
**Script:** `13_long_rolling_conversions.R`

**Concept:** Utiliser plus d'historique (4-5 saisons) pour stabiliser l'estim√© de conversion.

```r
# Au lieu de t-1, t-2, t-3
# Utiliser t-1, t-2, t-3, t-4, t-5

recency_weight_long <- c(0.3, 0.25, 0.2, 0.15, 0.1)
```

**Trade-off:** Plus de donn√©es = plus stable, mais moins r√©cent (age curves plus importantes).

---

## Template pour nouveau mod√®le

```r
# Titre: Nom du mod√®le
# Cible: features sp√©cifiques ou toutes

# Packages ---------------------------------------------------------------
library(dplyr)
library(ici_package_modele)  # ex: randomForest, xgboost, mgcv

cat("\n=== NOM DU MODELE ===\n\n")

# Charger donn√©es --------------------------------------------------------
df_valid_history <- readRDS("data/01_point_projections/projection/experiments/validation_data/df_valid_history.rds")
df_valid_targets <- readRDS("data/01_point_projections/projection/experiments/validation_data/df_valid_targets.rds")

# Features √† projeter
features_to_project <- c(
  "evtoi_per_gp", "pptoi_per_gp",
  "high_danger_shots_per60", "medium_danger_shots_per60",
  "x_goals_per60", "shot_attempts_per60",
  "conversion_high_danger", "conversion_medium", "conversion_overall"
)

# Fonction de calcul m√©triques (COPIER de 01_baseline_wma.R) -----------
calculate_metrics <- function(actual, predicted, model_name, feature_name) {
  # ... code identique ...
}

# Pr√©parer donn√©es selon approche games_played --------------------------
# Approche 1 (feature): ajouter gp_t1, gp_t2, gp_t3
# OU
# Approche 2 (poids): calculer poids ajust√©s

# Entra√Æner mod√®le pour chaque feature ----------------------------------
predictions <- data.frame(player_id = df_valid_targets$player_id)
metrics <- data.frame()

for (feature in features_to_project) {
  cat("Training:", feature, "\n")

  # Pr√©parer X, y pour ce feature
  # Entra√Æner mod√®le
  # Pr√©dire pour validation

  # Stocker pr√©dictions
  predictions[[paste0(feature, "_pred")]] <- preds

  # Calculer m√©triques
  metrics <- rbind(metrics, calculate_metrics(
    df_valid_targets[[feature]],
    preds,
    "nom_modele",
    feature
  ))
}

# Afficher r√©sultats -----------------------------------------------------
print(metrics, row.names = FALSE, digits = 3)

# Sauvegarder ------------------------------------------------------------
dir.create("data/01_point_projections/projection/experiments/results/nom_modele",
           showWarnings = FALSE, recursive = TRUE)

saveRDS(metrics, "data/.../results/nom_modele/metrics.rds")
saveRDS(predictions, "data/.../results/nom_modele/predictions.rds")

# Analyses par groupe (OPTIONNEL) ---------------------------------------
# Copier code de 01_baseline_wma.R lignes 219-354
```

---

## Format des outputs

### Structure de dossiers
```
data/01_point_projections/projection/experiments/results/
‚îú‚îÄ‚îÄ wma/
‚îÇ   ‚îú‚îÄ‚îÄ metrics.rds
‚îÇ   ‚îú‚îÄ‚îÄ eval_v1.rds
‚îÇ   ‚îú‚îÄ‚îÄ eval_v2.rds
‚îÇ   ‚îú‚îÄ‚îÄ metrics_by_position.rds
‚îÇ   ‚îú‚îÄ‚îÄ metrics_by_gp.rds
‚îÇ   ‚îú‚îÄ‚îÄ metrics_by_age.rds
‚îÇ   ‚îî‚îÄ‚îÄ metrics_by_seasons.rds
‚îú‚îÄ‚îÄ regression_to_mean/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ age_curves/
‚îú‚îÄ‚îÄ random_forest/
‚îú‚îÄ‚îÄ xgboost/
‚îú‚îÄ‚îÄ gam/
‚îú‚îÄ‚îÄ lstm/
‚îî‚îÄ‚îÄ ensemble/
```

### Format metrics.rds
```r
data.frame(
  model = "nom_modele",
  feature = "evtoi_per_gp",
  r2 = 0.705,
  mae = 71.26,
  mape = 10.1,
  n = 840
)
```

### Format predictions.rds
```r
data.frame(
  player_id = c(8478402, ...),
  evtoi_per_gp_pred = c(750.2, ...),
  pptoi_per_gp_pred = c(120.5, ...),
  # ... une colonne par feature
)
```

---

## M√©triques de succ√®s

### Objectifs par feature

**Time on Ice:**
- R¬≤ > 0.75 (excellent)
- R¬≤ > 0.65 (acceptable)

**Production (shots, xgoals):**
- R¬≤ > 0.80 (excellent)
- R¬≤ > 0.70 (acceptable)

**Conversion rates:**
- R¬≤ > 0.50 (excellent - tr√®s difficile!)
- R¬≤ > 0.30 (acceptable)
- R¬≤ > 0 (minimum absolu)

### Analyses par sous-groupes
Pour chaque mod√®le, analyser performance selon:
- **Position** (F vs D)
- **√Çge** (18-21, 22-24, 25-28, 29-32, 33-36, 37+)
- **Historique** (1, 2, 3 saisons)
- **Games played** (Low <150, Medium 150-225, High 225+)

---

## Workflow final

```bash
# 1. Pr√©parer donn√©es (si pas d√©j√† fait)
Rscript 00_prepare_validation_data.R

# 2. Baseline (d√©j√† fait)
Rscript 01_baseline_wma.R

# 3. Autres mod√®les (√† cr√©er)
Rscript 02_regression_to_mean.R
Rscript 03_age_curves.R
Rscript 04_random_forest.R
Rscript 05_xgboost.R
Rscript 06_gam.R
Rscript 07_lstm.R
Rscript 08_ensemble.R

# 4. Comparer et s√©lectionner meilleur par feature
Rscript 99_compare_and_select_best_per_feature.R
```

---

## D√©cision finale

Le script `99_compare_and_select_best_per_feature.R` va:

1. Charger toutes les m√©triques
2. Pour CHAQUE feature, s√©lectionner le mod√®le avec meilleur R¬≤
3. G√©n√©rer tableau r√©capitulatif:

| Feature | Meilleur mod√®le | R¬≤ | MAE |
|---------|----------------|-----|-----|
| evtoi_per_gp | XGBoost | 0.82 | 55.2 |
| x_goals_per60 | LSTM | 0.87 | 8.9 |
| conversion_overall | Regression_to_mean | 0.58 | 0.022 |
| ... | ... | ... | ... |

4. Cr√©er fichier de configuration pour production:
```r
# config_best_models_per_feature.rds
list(
  evtoi_per_gp = "xgboost",
  pptoi_per_gp = "random_forest",
  x_goals_per60 = "lstm",
  conversion_overall = "regression_to_mean",
  ...
)
```

---

## Ressources

- **Donn√©es sources:** `data/01_point_projections/processed/training_data.rds` (avec √¢ge)
- **Mod√®les bay√©siens finaux:** `data/01_point_projections/models/bayes_final_*.rds`
- **Issue #2 (Age Curves):** https://github.com/hubcad25/pool-lp/issues/2
